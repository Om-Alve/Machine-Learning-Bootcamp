{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f0c64b2-b1cc-4a99-8834-04b11b4db92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "793ebedf-b6c1-4055-b5ad-dc7af07f3262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = \"cats_dogs_light/train\"\n",
    "test = \"cats_dogs_light/test\"\n",
    "image_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55e449b2-14db-4d67-bb82-4f69eb6f3626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_data():\n",
    "    test_data_dogs = [] \n",
    "    test_data_cats=[]\n",
    "    for image in tqdm(os.listdir(test)): \n",
    "        if image[0] == \".\":\n",
    "            continue\n",
    "        path = os.path.join(test, image)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE) \n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        if image.split('.')[0] == \"cat\":\n",
    "            test_data_cats.append(img)\n",
    "        else:\n",
    "            test_data_dogs.append(img)\n",
    "    \n",
    "    test_data= np.concatenate((np.asarray(test_data_dogs),np.asarray(test_data_cats)),axis=0) \n",
    "    return test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ce2d197-ab96-43ea-818d-53655a66fa3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_data():\n",
    "    train_data_dogs = [] \n",
    "    train_data_cats=[]\n",
    "    for image in tqdm(os.listdir(train)): \n",
    "        path = os.path.join(train, image)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE) \n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "        if image.split('.')[0] == \"cat\":\n",
    "            train_data_cats.append(img)\n",
    "        else:\n",
    "            train_data_dogs.append(img)\n",
    "    \n",
    "    train_data= np.concatenate((np.asarray(train_data_dogs),np.asarray(train_data_cats)),axis=0)\n",
    "    return train_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "55565bdd-eb06-4305-84b5-16a14eec9291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:03<00:00, 319.63it/s]\n",
      "100%|██████████| 401/401 [00:00<00:00, 720.73it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data() \n",
    "test_data = test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e9b4c35-28aa-413a-a3f7-2ab1de1ca103",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 128, 128)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data=np.concatenate((train_data,test_data),axis=0)\n",
    "x_data = x_data / 255\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b879dc86-0b29-4500-9504-c85cfeda312e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 128, 128)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "461b5c9f-dc5c-41f9-a43b-03c45426b2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z1 = np.zeros(500)\n",
    "o1 = np.ones(500)\n",
    "Y_train = np.concatenate((o1, z1), axis=0)\n",
    "z = np.zeros(200)\n",
    "o = np.ones(200)\n",
    "Y_test = np.concatenate((o, z), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eeae91e-49cd-49fd-9706-15a03ecc6e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_data=np.concatenate((Y_train,Y_test),axis=0).reshape(x_data.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "129c8f43-b533-4f5f-8ecc-780f2d1cbff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (1400, 128, 128)\n",
      "Y shape:  (1400, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape: \" , x_data.shape)\n",
    "print(\"Y shape: \" , y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b313e508-c569-4919-9ec1-4b959222640b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=42)\n",
    "number_of_train = x_train.shape[0]\n",
    "number_of_test = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5932ff48-2c09-4734-8cbf-63edda1adc5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train flatten (1190, 16384)\n",
      "X test flatten (210, 16384)\n"
     ]
    }
   ],
   "source": [
    "x_train_flatten = x_train.reshape(number_of_train, -1)\n",
    "x_test_flatten = x_test .reshape(number_of_test,-1)\n",
    "print(\"X train flatten\",x_train_flatten.shape)\n",
    "print(\"X test flatten\",x_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48c47e5f-aeab-44ee-9165-91221b2153f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train:  (1190, 16384)\n",
      "x test:  (210, 16384)\n",
      "y train:  (1190, 1)\n",
      "y test:  (210, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train_flatten\n",
    "x_test = x_test_flatten\n",
    "y_test = y_test\n",
    "y_train = y_train\n",
    "print(\"x train: \",x_train.shape)\n",
    "print(\"x test: \",x_test.shape)\n",
    "print(\"y train: \",y_train.shape)\n",
    "print(\"y test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1950795f-d4fb-47bd-915b-f71b4aafad34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a5dca9c-8fb0-457e-bcf6-37a72fc8c4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(x_train,y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bab54809-2129-43fa-89e1-e51f49243ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6523809523809524"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4521cff-2a73-4db5-b144-603780287b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(x_test[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e741ad0-988c-453f-a6c6-b6eb3e632cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe925d8-ba3e-4328-9801-ba081988ee54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 208\n",
    "pred = \"This is a cat.\" if model.predict([x_test[i]]) == 0 else \"This is a dog.\"\n",
    "print(pred)\n",
    "plt.imshow(x_test[i].reshape(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ce79354-2c59-4e55-abb7-836424aaf801",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self,ninputs,nneurons,l1_w=0,l1_b=0,l2_w=0,l2_b=0):\n",
    "        # Initialising weights and biases\n",
    "        self.weights = 0.01 * np.random.randn(ninputs,nneurons)\n",
    "        self.biases = np.zeros((1,nneurons))\n",
    "        # Regularization\n",
    "        self.l1_w = l1_w\n",
    "        self.l1_b = l1_b\n",
    "        self.l2_w = l2_w\n",
    "        self.l2_b = l2_b\n",
    "        \n",
    "    # Forward Propagation    \n",
    "    def forward(self,inputs,training):\n",
    "        self.output = np.dot(inputs,self.weights) + self.biases\n",
    "        self.inputs = inputs\n",
    "    \n",
    "    # Backpropagation\n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = np.dot(dvalues,self.weights.T)\n",
    "        self.dweights = np.dot(self.inputs.T,dvalues)\n",
    "        self.dbiases = np.sum(dvalues,axis=0,keepdims=True)\n",
    "        \n",
    "        if self.l1_w > 0:\n",
    "            dl1w = np.ones_like(self.weights)\n",
    "            dl1w[self.weights < 0] = -1\n",
    "            self.dweights += dl1w\n",
    "        if self.l1_b > 0:\n",
    "            dl1b = np.ones_like(self.biases)\n",
    "            dl1b[self.biases < 0] = -1\n",
    "            self.dbiases += sl1b\n",
    "        if self.l2_w > 0:\n",
    "            self.dweights += self.weights * 2 * self.l2_w\n",
    "        if self.l2_b > 0:\n",
    "            self.dbiases += self.biases * 2 * self.l2_b\n",
    "            \n",
    "\n",
    "class Dropout_layer:\n",
    "    def __init__(self,drop_rate=0):\n",
    "        self.drop_rate = 1 - drop_rate\n",
    "    def forward(self,inputs,training):\n",
    "        if not training:\n",
    "            self.output = input.copy()\n",
    "            return\n",
    "        self.dropmask = np.random.binomial(1,self.drop_rate,size =inputs.shape)/(self.drop_rate)\n",
    "        self.output = inputs * self.dropmask\n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = dvalues * self.dropmask\n",
    "        \n",
    "class Activation_Relu:\n",
    "    def forward(self,inputs,training):\n",
    "        self.output = np.maximum(0,inputs)\n",
    "        self.inputs = inputs\n",
    "    \n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "        \n",
    "class Activation_Sigmoid:\n",
    "    def forward(self,inputs,training):\n",
    "        self.inputs= inputs\n",
    "        self.outputs = 1/(1+np.exp(-inputs))\n",
    "    def backward(self,dvalues):\n",
    "        self.dinputs = dvalues * self.outputs * (1 - self.outputs)\n",
    "        \n",
    "class Loss_BinaryCrossentropy():\n",
    "    def calculate(self, output, y):\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "\n",
    "    def regularization_loss(self):\n",
    "        \n",
    "        loss = 0\n",
    "        for layer in self.trainable_layers:\n",
    "            if layer.l1_w > 0:\n",
    "                loss += layer.l1_w * np.sum(np.abs(layer.weights))\n",
    "            if layer.l1_b > 0:\n",
    "                loss += layer.l1_b * np.sum(np.abs(layer.biases))\n",
    "            if layer.l2_w > 0:\n",
    "                loss += layer.l2_w * np.sum(layer.weights * layer.weights)\n",
    "            if layer.l2_b > 0:\n",
    "                loss += layer.l2_b * np.sum(layer.biases * layer.biases)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def remember_trainable_layers(self, trainable_layers):\n",
    "        self.trainable_layers = trainable_layers\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # Calculate sample-wise loss\n",
    "        sample_losses = -(y_true * np.log(y_pred_clipped) +\n",
    "        (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        sample_losses = np.mean(sample_losses, axis=-1)\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "        # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -(y_true / clipped_dvalues -\n",
    "        (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "        \n",
    "class Activation_Softmax:\n",
    "    def forward(self,inputs,y_true):\n",
    "        expvals = np.exp(inputs - np.max(inputs, axis=1,\n",
    "        keepdims=True) )\n",
    "        self.output = expvals/np.sum(expvals,axis=1,keepdims=True)\n",
    "        \n",
    "    def predictions(self, outputs):\n",
    "        return np.argmax(outputs, axis=1)\n",
    "    \n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "            range(samples),\n",
    "            y_true\n",
    "            ]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "            y_pred_clipped * y_true,\n",
    "            axis=1\n",
    "            )\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "    def calculate_accumulated(self,*,regularization=False):\n",
    "        data_loss = self.accumulated_sum / self.accumulated_count\n",
    "        if not regularization:\n",
    "            return data_loss\n",
    "        return data_loss,self.regularization_loss()\n",
    "    \n",
    "    def calculate(self, output, y, *, regularization=False):\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        \n",
    "        self.accumulated_sum += np.sum(sample_losses)\n",
    "        self.accumulated_count += len(sample_losses)\n",
    "\n",
    "        # If just data loss - return it\n",
    "        if not regularization:\n",
    "            return data_loss\n",
    "        # Return the data and regularization losses\n",
    "        return data_loss, self.regularization_loss()\n",
    "        \n",
    "        return np.mean(-np.log(y_pred[range(len(y_pred)),y_true]))\n",
    "    def regularization_loss(self):\n",
    "        \n",
    "        loss = 0\n",
    "        for layer in self.trainable_layers:\n",
    "            if layer.l1_w > 0:\n",
    "                loss += layer.l1_w * np.sum(np.abs(layer.weights))\n",
    "            if layer.l1_b > 0:\n",
    "                loss += layer.l1_b * np.sum(np.abs(layer.biases))\n",
    "            if layer.l2_w > 0:\n",
    "                loss += layer.l2_w * np.sum(layer.weights * layer.weights)\n",
    "            if layer.l2_b > 0:\n",
    "                loss += layer.l2_b * np.sum(layer.biases * layer.biases)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def remember_trainable_layers(self, trainable_layers):\n",
    "        self.trainable_layers = trainable_layers\n",
    "        \n",
    "    def new_pass(self):\n",
    "        self.accumulated_sum = 0\n",
    "        self.accumulated_count = 0\n",
    "        \n",
    "        \n",
    "class Activation_softmax_cross_entropy:\n",
    "#     def __init__(self):\n",
    "#         self.activation = Activation_Softmax()\n",
    "#         self.lossfunc = CrossEntropyLoss()\n",
    "    \n",
    "#     def forward(self,inputs,y_true):\n",
    "#         self.activation.forward(inputs,y_true)\n",
    "#         self.output = self.activation.output\n",
    "#         return self.lossfunc.calculate(self.output,y_true)\n",
    "    \n",
    "    def backward(self,dvalues,y_true):\n",
    "        samples = len(y_true)\n",
    "        \n",
    "        # Turning one hot encoded arrays to sparse vectors\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true,axis=1)\n",
    "        \n",
    "        self.dinputs = dvalues.copy()\n",
    "        self.dinputs[range(samples),y_true] -= 1\n",
    "        \n",
    "        self.dinputs/=samples\n",
    "        \n",
    "        \n",
    "class Adam_Optimizer:\n",
    "    def __init__(self,lr=0.001,decay_rate=0,epsilon= 1e-7,beta1=0.9,beta2=0.999):\n",
    "        self.initiallr = lr\n",
    "        self.currentlr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "    \n",
    "    def pre_update(self):\n",
    "        self.currentlr = self.initiallr * (1/(1+(self.decay_rate * self.iterations)))\n",
    "\n",
    "    def update_params(self,layer):\n",
    "        \n",
    "        if not hasattr(layer,'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "            layer.weight_momentum = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentum = np.zeros_like(layer.biases)\n",
    "            \n",
    "        layer.weight_momentum = self.beta1 * layer.weight_momentum + (1-self.beta1) * layer.dweights\n",
    "        layer.bias_momentum = self.beta1 * layer.bias_momentum + (1 - self.beta1) * layer.dbiases\n",
    "        \n",
    "        layer.weight_momentum_prime = layer.weight_momentum / (1 - self.beta1 ** (self.iterations + 1))\n",
    "        layer.bias_momentum_prime = layer.bias_momentum / (1 - self.beta1 ** (self.iterations + 1))\n",
    "        \n",
    "        layer.weight_cache = layer.weight_cache * self.beta2 + (1-self.beta2) * (layer.dweights ** 2)\n",
    "        layer.bias_cache = layer.bias_cache * self.beta2 + (1-self.beta2) * (layer.dbiases ** 2)\n",
    "        \n",
    "        layer.weight_cache_prime = layer.weight_cache / (1 - self.beta2 ** (self.iterations + 1))\n",
    "        layer.bias_cache_prime = layer.bias_cache / (1 - self.beta2 ** (self.iterations + 1))\n",
    "\n",
    "        layer.weights += - self.currentlr * layer.weight_momentum_prime  / (np.sqrt(layer.weight_cache_prime) + self.epsilon)\n",
    "        layer.biases += -self.currentlr * layer.bias_momentum_prime / (np.sqrt(layer.bias_cache_prime) + self.epsilon)\n",
    "        \n",
    "    def post_update(self):\n",
    "        self.iterations += 1\n",
    "        \n",
    "        \n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.softmax_classifier_output = None\n",
    "    \n",
    "    def add(self,layer):\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def set(self,*,loss,optimizer,accuracy):\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.accuracy = accuracy\n",
    "    \n",
    "    def train(self,X,y,*,epochs,print_every,validation_data = None,batch_size = None):\n",
    "        self.accuracy.init(y)\n",
    "        \n",
    "        train_steps = 1\n",
    "        \n",
    "        if validation_data is not None:\n",
    "            validation_steps = 1\n",
    "            X_val,y_val = validation_data\n",
    "        \n",
    "        if batch_size is not None:\n",
    "            train_steps = len(X) // batch_size\n",
    "            \n",
    "            if train_steps * batch_size < len(X):\n",
    "                train_steps += 1\n",
    "                \n",
    "            if validation_data is not None:\n",
    "                validation_steps = len(X_val) // batch_size\n",
    "                \n",
    "                if validation_steps * batch_size < len(X_val):\n",
    "                    validation_steps += 1\n",
    "                \n",
    "        \n",
    "        for epoch in range(1,epochs+1):\n",
    "            \n",
    "            print(\"Epoch : \",epoch)\n",
    "            \n",
    "            self.loss.new_pass()\n",
    "            self.accuracy.new_pass()\n",
    "            \n",
    "            for step in range(train_steps):\n",
    "                \n",
    "                if batch_size is None:\n",
    "                    batch_X = X\n",
    "                    batch_y = y\n",
    "                else:\n",
    "                    batch_X = X[step * batch_size : (step+1) * batch_size]\n",
    "                    batch_y = y[step * batch_size : (step+1) * batch_size]\n",
    "\n",
    "                    \n",
    "                output = self.forward(batch_X,training = True)\n",
    "                data_loss,regularization_loss = self.loss.calculate(output,batch_y,regularization=True)\n",
    "                loss = data_loss + regularization_loss\n",
    "\n",
    "                predictions = self.output_activation.predictions(output)\n",
    "\n",
    "                accuracy = self.accuracy.calculate(predictions,batch_y)\n",
    "\n",
    "                self.backward(output,batch_y)\n",
    "\n",
    "                self.optimizer.pre_update()\n",
    "                for layer in self.trainable_layers:\n",
    "                    self.optimizer.update_params(layer)\n",
    "                self.optimizer.post_update\n",
    "\n",
    "                if not step % print_every or step == train_steps - 1:\n",
    "                    print(f'iteration: {step}, ' +\n",
    "                    f'acc: {accuracy:.3f}, ' +\n",
    "                    f'loss: {loss:.3f} (' +\n",
    "                    f'data_loss: {data_loss:.3f}, ' +\n",
    "                    f'reg_loss: {regularization_loss:.3f}), ' +\n",
    "                    f'lr: {self.optimizer.currentlr}')\n",
    "            \n",
    "            epoch_accuracy = self.accuracy.calculate_accumulated()\n",
    "            epoch_data_loss, epoch_regularization_loss = self.loss.calculate_accumulated(regularization=True)\n",
    "            epoch_loss = epoch_data_loss + epoch_regularization_loss\n",
    "            \n",
    "            print(f'training, ' +\n",
    "                    f'acc: {epoch_accuracy:.3f}, ' +\n",
    "                    f'loss: {epoch_loss:.3f} (' +\n",
    "                    f'data_loss: {epoch_data_loss:.3f}, ' +\n",
    "                    f'reg_loss: {epoch_regularization_loss:.3f}), ' +\n",
    "                    f'lr: {self.optimizer.currentlr}')\n",
    "\n",
    "            \n",
    "            \n",
    "        if validation_data is not None:\n",
    "            \n",
    "            self.accuracy.new_pass()\n",
    "            self.loss.new_pass()\n",
    "            \n",
    "            for step in range(validation_steps):\n",
    "                if batch_size is None:\n",
    "                    batch_X = X_val\n",
    "                    batch_y = y_val\n",
    "                else:\n",
    "                    batch_X = X_val[step * batch_size : (step + 1) * batch_size]\n",
    "                    batch_y = y_val[step * batch_size : (step + 1) * batch_size]\n",
    "                    \n",
    "            \n",
    "            output = self.forward(batch_X,training=False)\n",
    "            loss = self.loss.calculate(output, batch_y)\n",
    "            predictions = self.output_activation.predictions(\n",
    "            output)\n",
    "            accuracy = self.accuracy.calculate(predictions, batch_y)\n",
    "            validation_accuracy = self.accuracy.calculate_accumulated()\n",
    "            validation_loss = self.loss.calculate_accumulated()\n",
    "            print(f'validation, ' +\n",
    "            f'acc: {validation_accuracy:.3f}, ' +\n",
    "            f'loss: {validation_loss:.3f}')\n",
    "\n",
    "        \n",
    "    def finalize(self):\n",
    "        self.input_layer = Input_Layer()\n",
    "        self.trainable_layers = []\n",
    "        nlayers = len(self.layers)\n",
    "        \n",
    "        for i in range(nlayers):\n",
    "            if i==0 :\n",
    "                self.layers[i].prev = self.input_layer\n",
    "                self.layers[i].next = self.layers[i+1]\n",
    "            elif i < nlayers - 1:\n",
    "                self.layers[i].prev = self.layers[i-1]\n",
    "                self.layers[i].next = self.layers[i+1]\n",
    "            else:\n",
    "                self.layers[i].prev = self.layers[i-1]\n",
    "                self.layers[i].next = self.loss\n",
    "                self.output_activation = self.layers[i]\n",
    "            \n",
    "            if hasattr(self.layers[i],\"weights\"):\n",
    "                self.trainable_layers.append(self.layers[i])\n",
    "        self.loss.remember_trainable_layers(self.trainable_layers)   \n",
    "        \n",
    "        if isinstance(self.layers[-1], Activation_Softmax) and \\\n",
    "        isinstance(self.loss, CrossEntropyLoss):\n",
    "            self.softmax_classifier_output = \\\n",
    "            Activation_softmax_cross_entropy()\n",
    "\n",
    "            \n",
    "    def forward(self,X,training):\n",
    "        self.input_layer.forward(X)\n",
    "        for layer in self.layers:\n",
    "            layer.forward(layer.prev.output,training)\n",
    "        return layer.output\n",
    "    def backward(self,output,y):\n",
    "        \n",
    "        if self.softmax_classifier_output is not None:\n",
    "            self.softmax_classifier_output.backward(output, y)\n",
    "            self.layers[-1].dinputs = \\\n",
    "            self.softmax_classifier_output.dinputs\n",
    "            for layer in reversed(self.layers[:-1]):\n",
    "                layer.backward(layer.next.dinputs)\n",
    "            return\n",
    "        \n",
    "        \n",
    "        self.loss.backward(output,y)\n",
    "        \n",
    "        for layer in reversed(self.layers):\n",
    "            layer.backward(layer.next.dinputs)\n",
    "        \n",
    "class Input_Layer:\n",
    "    def forward(self,inputs):\n",
    "        self.output = inputs\n",
    "        \n",
    "class Accuracy:\n",
    "    def calculate(self,predictions,y):\n",
    "        comparisions = self.compare(predictions,y)\n",
    "        accuracy = np.mean(comparisions)\n",
    "        self.accumulated_sum += accuracy\n",
    "        self.accumulated_count += 1\n",
    "        return accuracy\n",
    "    \n",
    "    def calculate_accumulated(self):\n",
    "        accuracy = self.accumulated_sum / self.accumulated_count\n",
    "        return accuracy\n",
    "    \n",
    "    def new_pass(self):\n",
    "        self.accumulated_count = 0\n",
    "        self.accumulated_sum = 0\n",
    "    \n",
    "class Accuracy_Regression(Accuracy):\n",
    "    def __init__(self):\n",
    "        self.precision = None\n",
    "        \n",
    "    def init(self, y, reinit=False):\n",
    "        if self.precision is None or reinit:\n",
    "            self.precision = np.std(y) / 250\n",
    "\n",
    "    def compare(self, predictions, y):\n",
    "        return np.absolute(predictions - y) < self.precision\n",
    "\n",
    "class Accuracy_Classification(Accuracy):\n",
    "    def init(self,y):\n",
    "        pass\n",
    "    def compare(self,predictions,y):\n",
    "        if len(y.shape) == 2:\n",
    "            y = np.argmax(y,axis=1)\n",
    "        return np.mean(predictions == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6274874d-511f-4cae-8067-4ff730a2ae9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1\n",
      "iteration: 0, acc: 0.688, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omalv\\AppData\\Local\\Temp\\ipykernel_5660\\2745196489.py:150: RuntimeWarning: divide by zero encountered in log\n",
      "  negative_log_likelihoods = -np.log(correct_confidences)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 9, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "training, acc: 0.969, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "Epoch :  2\n",
      "iteration: 0, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "iteration: 9, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "training, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "Epoch :  3\n",
      "iteration: 0, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "iteration: 9, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "training, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "Epoch :  4\n",
      "iteration: 0, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "iteration: 9, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "training, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "Epoch :  5\n",
      "iteration: 0, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "iteration: 9, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "training, acc: 1.000, loss: inf (data_loss: inf, reg_loss: 0.000), lr: 0.001\n",
      "validation, acc: 1.000, loss: inf\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.add(Dense_Layer(16384,64))\n",
    "model.add(Activation_Relu())\n",
    "model.add(Dense_Layer(64,64))\n",
    "model.add(Activation_Relu())\n",
    "model.add(Dense_Layer(64,2))\n",
    "model.add(Activation_Softmax())\n",
    "\n",
    "model.set(accuracy=Accuracy_Classification(),loss=CrossEntropyLoss(),optimizer=Adam_Optimizer(decay_rate=1e-3))\n",
    "\n",
    "model.finalize()\n",
    "\n",
    "model.train(x_train,y_train,batch_size=128,epochs=5,print_every=100,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21d14c2d-1e28-4c00-b6be-12a1e2937115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.forward(x_test,training=False)\n",
    "predictions = np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f43a4d6-311f-4989-8750-e7030c7209b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 2.14193943e-075],\n",
       "       [1.00000000e+000, 3.87107361e-034],\n",
       "       [1.00000000e+000, 2.73899882e-073],\n",
       "       [1.00000000e+000, 1.75754367e-065],\n",
       "       [1.00000000e+000, 2.36454653e-077],\n",
       "       [1.00000000e+000, 6.87926213e-095],\n",
       "       [1.00000000e+000, 2.96612499e-073],\n",
       "       [1.00000000e+000, 9.54570364e-054],\n",
       "       [1.00000000e+000, 1.64647122e-054],\n",
       "       [1.00000000e+000, 3.94578314e-040],\n",
       "       [1.00000000e+000, 7.24771772e-071],\n",
       "       [1.00000000e+000, 2.42040429e-060],\n",
       "       [1.00000000e+000, 5.68495339e-067],\n",
       "       [1.00000000e+000, 3.01610508e-058],\n",
       "       [1.00000000e+000, 1.92815664e-045],\n",
       "       [1.00000000e+000, 4.91212603e-038],\n",
       "       [1.00000000e+000, 1.93870286e-065],\n",
       "       [1.00000000e+000, 1.53829962e-081],\n",
       "       [1.00000000e+000, 3.98927461e-082],\n",
       "       [1.00000000e+000, 2.34907143e-094],\n",
       "       [1.00000000e+000, 8.17371717e-057],\n",
       "       [1.00000000e+000, 1.36486836e-077],\n",
       "       [1.00000000e+000, 1.71905529e-079],\n",
       "       [1.00000000e+000, 2.35888872e-086],\n",
       "       [1.00000000e+000, 3.10308498e-086],\n",
       "       [1.00000000e+000, 2.50670880e-068],\n",
       "       [1.00000000e+000, 2.56141673e-057],\n",
       "       [1.00000000e+000, 1.07105875e-080],\n",
       "       [1.00000000e+000, 1.32803763e-052],\n",
       "       [1.00000000e+000, 1.70787155e-066],\n",
       "       [1.00000000e+000, 9.50277102e-072],\n",
       "       [1.00000000e+000, 1.09443955e-081],\n",
       "       [1.00000000e+000, 1.39840046e-056],\n",
       "       [1.00000000e+000, 9.33902205e-097],\n",
       "       [1.00000000e+000, 1.00631761e-071],\n",
       "       [1.00000000e+000, 2.74244342e-104],\n",
       "       [1.00000000e+000, 3.87168400e-107],\n",
       "       [1.00000000e+000, 1.07895429e-070],\n",
       "       [1.00000000e+000, 1.11047797e-059],\n",
       "       [1.00000000e+000, 6.50863263e-090],\n",
       "       [1.00000000e+000, 2.39995580e-028],\n",
       "       [1.00000000e+000, 1.48493589e-088],\n",
       "       [1.00000000e+000, 1.79493729e-063],\n",
       "       [1.00000000e+000, 3.63570729e-081],\n",
       "       [1.00000000e+000, 1.21411922e-094],\n",
       "       [1.00000000e+000, 1.91219612e-076],\n",
       "       [1.00000000e+000, 5.72745581e-073],\n",
       "       [1.00000000e+000, 7.48317164e-043],\n",
       "       [1.00000000e+000, 1.81963502e-056],\n",
       "       [1.00000000e+000, 1.89747087e-059],\n",
       "       [1.00000000e+000, 6.25014694e-077],\n",
       "       [1.00000000e+000, 8.53398235e-074],\n",
       "       [1.00000000e+000, 1.21336545e-056],\n",
       "       [1.00000000e+000, 2.07973091e-097],\n",
       "       [1.00000000e+000, 4.24754040e-056],\n",
       "       [1.00000000e+000, 6.76508173e-055],\n",
       "       [1.00000000e+000, 2.84475124e-055],\n",
       "       [1.00000000e+000, 2.38625085e-102],\n",
       "       [1.00000000e+000, 2.12759544e-052],\n",
       "       [1.00000000e+000, 7.24568324e-049],\n",
       "       [1.00000000e+000, 7.20641066e-062],\n",
       "       [1.00000000e+000, 5.16904854e-082],\n",
       "       [1.00000000e+000, 1.32572969e-051],\n",
       "       [1.00000000e+000, 3.62067842e-064],\n",
       "       [1.00000000e+000, 4.60434453e-064],\n",
       "       [1.00000000e+000, 1.36805614e-073],\n",
       "       [1.00000000e+000, 2.00300697e-058],\n",
       "       [1.00000000e+000, 3.33451114e-066],\n",
       "       [1.00000000e+000, 9.63770553e-075],\n",
       "       [1.00000000e+000, 6.68888036e-075],\n",
       "       [1.00000000e+000, 8.87926931e-076],\n",
       "       [1.00000000e+000, 9.19548207e-067],\n",
       "       [1.00000000e+000, 1.69224577e-065],\n",
       "       [1.00000000e+000, 1.64075917e-069],\n",
       "       [1.00000000e+000, 1.91819335e-075],\n",
       "       [1.00000000e+000, 1.24525792e-079],\n",
       "       [1.00000000e+000, 1.99504375e-075],\n",
       "       [1.00000000e+000, 1.28630123e-066],\n",
       "       [1.00000000e+000, 9.97367651e-083],\n",
       "       [1.00000000e+000, 2.79319457e-060],\n",
       "       [1.00000000e+000, 9.36739644e-076],\n",
       "       [1.00000000e+000, 1.23536061e-085],\n",
       "       [1.00000000e+000, 4.55684132e-057],\n",
       "       [1.00000000e+000, 1.07864057e-090],\n",
       "       [1.00000000e+000, 1.96508145e-048],\n",
       "       [1.00000000e+000, 5.09245946e-055],\n",
       "       [1.00000000e+000, 1.15987139e-072],\n",
       "       [1.00000000e+000, 3.62688642e-083],\n",
       "       [1.00000000e+000, 6.27215884e-049],\n",
       "       [1.00000000e+000, 2.03307227e-068],\n",
       "       [1.00000000e+000, 3.34665514e-069],\n",
       "       [1.00000000e+000, 1.28447930e-050],\n",
       "       [1.00000000e+000, 4.19578612e-058],\n",
       "       [1.00000000e+000, 4.40018627e-065],\n",
       "       [1.00000000e+000, 3.09673760e-074],\n",
       "       [1.00000000e+000, 3.99977303e-060],\n",
       "       [1.00000000e+000, 1.72282255e-081],\n",
       "       [1.00000000e+000, 1.71669763e-063],\n",
       "       [1.00000000e+000, 1.95440518e-070],\n",
       "       [1.00000000e+000, 3.14545235e-046],\n",
       "       [1.00000000e+000, 8.94687469e-083],\n",
       "       [1.00000000e+000, 5.15083360e-110],\n",
       "       [1.00000000e+000, 2.36180311e-066],\n",
       "       [1.00000000e+000, 1.45336228e-051],\n",
       "       [1.00000000e+000, 1.62465554e-068],\n",
       "       [1.00000000e+000, 8.18376263e-036],\n",
       "       [1.00000000e+000, 9.95772729e-069],\n",
       "       [1.00000000e+000, 3.47154839e-077],\n",
       "       [1.00000000e+000, 9.97472927e-071],\n",
       "       [1.00000000e+000, 7.79508119e-064],\n",
       "       [1.00000000e+000, 8.60353249e-048],\n",
       "       [1.00000000e+000, 2.02436460e-071],\n",
       "       [1.00000000e+000, 1.42339582e-056],\n",
       "       [1.00000000e+000, 1.19060358e-072],\n",
       "       [1.00000000e+000, 2.42266469e-086],\n",
       "       [1.00000000e+000, 7.61701626e-092],\n",
       "       [1.00000000e+000, 5.64345341e-090],\n",
       "       [1.00000000e+000, 6.58495421e-062],\n",
       "       [1.00000000e+000, 4.30349951e-058],\n",
       "       [1.00000000e+000, 1.36173614e-053],\n",
       "       [1.00000000e+000, 4.24083773e-061],\n",
       "       [1.00000000e+000, 1.89902811e-090],\n",
       "       [1.00000000e+000, 5.58736986e-065],\n",
       "       [1.00000000e+000, 1.42813658e-081],\n",
       "       [1.00000000e+000, 4.27099734e-076],\n",
       "       [1.00000000e+000, 3.29610026e-060],\n",
       "       [1.00000000e+000, 2.01152912e-071],\n",
       "       [1.00000000e+000, 6.91988894e-040],\n",
       "       [1.00000000e+000, 1.35936785e-052],\n",
       "       [1.00000000e+000, 1.41536311e-066],\n",
       "       [1.00000000e+000, 5.64175645e-060],\n",
       "       [1.00000000e+000, 9.18946149e-064],\n",
       "       [1.00000000e+000, 8.61881262e-057],\n",
       "       [1.00000000e+000, 7.48442769e-072],\n",
       "       [1.00000000e+000, 2.03977747e-064],\n",
       "       [1.00000000e+000, 1.08951714e-035],\n",
       "       [1.00000000e+000, 4.63938974e-072],\n",
       "       [1.00000000e+000, 3.89839207e-078],\n",
       "       [1.00000000e+000, 1.79066702e-062],\n",
       "       [1.00000000e+000, 2.48096958e-087],\n",
       "       [1.00000000e+000, 1.41587916e-067],\n",
       "       [1.00000000e+000, 9.63365896e-071],\n",
       "       [1.00000000e+000, 2.45616556e-063],\n",
       "       [1.00000000e+000, 9.70627557e-054],\n",
       "       [1.00000000e+000, 1.27465987e-072],\n",
       "       [1.00000000e+000, 8.33239998e-068],\n",
       "       [1.00000000e+000, 5.18625238e-071],\n",
       "       [1.00000000e+000, 4.99613967e-050],\n",
       "       [1.00000000e+000, 4.67516363e-052],\n",
       "       [1.00000000e+000, 1.12658080e-051],\n",
       "       [1.00000000e+000, 1.87374320e-068],\n",
       "       [1.00000000e+000, 1.31190784e-059],\n",
       "       [1.00000000e+000, 6.85751904e-056],\n",
       "       [1.00000000e+000, 2.94440706e-086],\n",
       "       [1.00000000e+000, 2.26677871e-061],\n",
       "       [1.00000000e+000, 1.09658169e-073],\n",
       "       [1.00000000e+000, 9.38227987e-086],\n",
       "       [1.00000000e+000, 2.16997698e-044],\n",
       "       [1.00000000e+000, 1.87630095e-058],\n",
       "       [1.00000000e+000, 2.81594267e-067],\n",
       "       [1.00000000e+000, 3.79178708e-064],\n",
       "       [1.00000000e+000, 1.34976161e-077],\n",
       "       [1.00000000e+000, 1.40313918e-024],\n",
       "       [1.00000000e+000, 1.93860132e-062],\n",
       "       [1.00000000e+000, 3.46773694e-053],\n",
       "       [1.00000000e+000, 5.58453319e-030],\n",
       "       [1.00000000e+000, 1.71101372e-074],\n",
       "       [1.00000000e+000, 1.16707144e-050],\n",
       "       [1.00000000e+000, 9.92247492e-064],\n",
       "       [1.00000000e+000, 9.40017686e-070],\n",
       "       [1.00000000e+000, 3.82303436e-076],\n",
       "       [1.00000000e+000, 9.57111339e-085],\n",
       "       [1.00000000e+000, 8.25696700e-056],\n",
       "       [1.00000000e+000, 1.77022434e-058],\n",
       "       [1.00000000e+000, 4.13922669e-097],\n",
       "       [1.00000000e+000, 7.06468744e-068],\n",
       "       [1.00000000e+000, 1.94873019e-078],\n",
       "       [1.00000000e+000, 5.89308752e-062],\n",
       "       [1.00000000e+000, 3.24274949e-091],\n",
       "       [1.00000000e+000, 4.74045147e-084],\n",
       "       [1.00000000e+000, 1.72915242e-064],\n",
       "       [1.00000000e+000, 1.41267765e-062],\n",
       "       [1.00000000e+000, 4.18039390e-055],\n",
       "       [1.00000000e+000, 5.75612618e-040],\n",
       "       [1.00000000e+000, 6.42209583e-057],\n",
       "       [1.00000000e+000, 1.38687996e-047],\n",
       "       [1.00000000e+000, 1.51822399e-061],\n",
       "       [1.00000000e+000, 7.11111600e-063],\n",
       "       [1.00000000e+000, 2.62339934e-082],\n",
       "       [1.00000000e+000, 2.49096278e-081],\n",
       "       [1.00000000e+000, 1.33942164e-084],\n",
       "       [1.00000000e+000, 4.13824280e-042],\n",
       "       [1.00000000e+000, 1.97685337e-061],\n",
       "       [1.00000000e+000, 1.39893424e-055],\n",
       "       [1.00000000e+000, 9.31988039e-094],\n",
       "       [1.00000000e+000, 1.95063644e-060],\n",
       "       [1.00000000e+000, 2.27304274e-084],\n",
       "       [1.00000000e+000, 4.81652934e-069],\n",
       "       [1.00000000e+000, 6.86247999e-060],\n",
       "       [1.00000000e+000, 1.59940345e-087],\n",
       "       [1.00000000e+000, 6.78658909e-094],\n",
       "       [1.00000000e+000, 3.69685393e-084],\n",
       "       [1.00000000e+000, 2.43881862e-038],\n",
       "       [1.00000000e+000, 1.68304214e-068],\n",
       "       [1.00000000e+000, 7.16155574e-085],\n",
       "       [1.00000000e+000, 6.37244766e-052],\n",
       "       [1.00000000e+000, 3.50194213e-088],\n",
       "       [1.00000000e+000, 3.13008045e-077],\n",
       "       [1.00000000e+000, 6.96478591e-087],\n",
       "       [1.00000000e+000, 1.48942691e-056]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

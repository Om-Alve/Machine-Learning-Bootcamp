{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "362b0811-e614-4973-b778-d95b083cbf31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42bf5119-356e-43d0-8c34-7509e4a02205",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c30e631-957d-4c22-bb79-82d1fd32d629",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9996612071990967}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I am not sure about this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907c85ce-b993-450c-9476-633514768f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small and revision d769bba (https://huggingface.co/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52834adeda7041309dbfd46156818cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af105e003c1e43ebb344447ec8a98a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c552a4e4201f476596fc357d4aadcfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3526674477b94b25a5dff5ccd6188365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e086adc19f4419840eafbfc55994c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b64fd702-0e68-47d1-beef-2cd3bf6fb69d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \"zero-shot classification is a type of machine learning and natural language processing (NLP) task . models are trained on labeled data for specific categories or classes . a model is trained on a dataset of animal images to classify a new, unseen animal species based on its textual description . the model can use the learned associations to make predictions for classes that weren't part of the training dataset . it's possible to collect extensive training data for all possible categories .\"}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "\"\"\"\n",
    "Zero-shot classification is a type of machine learning and natural language processing (NLP) task in which a model is trained to classify or recognize objects, entities, or concepts that it has never seen during training. In traditional supervised learning, models are trained on labeled data for specific categories or classes. However, zero-shot classification takes it a step further by enabling models to make predictions for classes that were not part of the training dataset.\n",
    "\n",
    "Here's how zero-shot classification works\n",
    "1. **Class Descriptions**: In zero-shot classification, classes or categories are often associated with textual descriptions or attributes rather than explicit training examples. For example, instead of having images of various dog breeds to train on, you might have textual descriptions like \"Golden Retriever\" or \"Poodle.\"\n",
    "\n",
    "2. **Semantic Embeddings**: To enable zero-shot classification, each class description or attribute is transformed into a numerical vector or embedding using techniques like word embeddings (e.g., Word2Vec, GloVe) or more advanced methods like BERT embeddings for NLP tasks.\n",
    "\n",
    "3. **Model Training**: A machine learning model (e.g., a neural network) is then trained using these class embeddings along with the available training data. The model learns to associate the textual descriptions with the corresponding class labels.\n",
    "\n",
    "4. **Zero-Shot Inference**: During inference, when the model encounters an example that belongs to a class it has never seen during training, it can use the learned associations to make predictions. By measuring the similarity between the example and the class descriptions, the model assigns a label to the example.\n",
    "\n",
    "Zero-shot classification has various practical applications, especially in domains where new classes or concepts emerge over time or where it's impractical to collect extensive training data for all possible categories. For example, in image classification, zero-shot learning allows a model trained on a dataset of animal images to classify a new, unseen animal species based on its textual description.\n",
    "\n",
    "Few-shot and few-shot learning are related concepts, where the model is trained with only a very limited number of examples for each class, rather than zero examples. Zero-shot learning represents the extreme case of few-shot learning where no examples of a class are available during training.\n",
    "\"\"\"\n",
    ",min_length = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7ee24-4f87-4c1f-a491-ba10e86c0d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py39] *",
   "language": "python",
   "name": "conda-env-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

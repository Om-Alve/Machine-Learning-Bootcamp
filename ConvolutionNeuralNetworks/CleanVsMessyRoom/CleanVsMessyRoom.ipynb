{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd9d5c92-5cad-450b-990c-d0636289c6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten,BatchNormalization,Dropout\n",
    "from keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af03ede7-92fd-46f4-809a-156946901097",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 files belonging to 2 classes.\n",
      "Found 30 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = keras.utils.image_dataset_from_directory(\n",
    "    directory='images/train',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size = 10,\n",
    "    image_size=(256,256)\n",
    ")\n",
    "test_data = keras.utils.image_dataset_from_directory(\n",
    "    directory='images/val',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size = 10,\n",
    "    image_size=(256,256)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1230bb65-1d6f-486c-9f97-984dd3410e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(image,label):\n",
    "    image = tf.cast(image/255,tf.float32)\n",
    "    return image,label\n",
    "train_data = train_data.map(normalize)\n",
    "test_data = test_data.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3459b925-0d43-459a-9cd8-118d75b715b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',activation='relu',input_shape=(256,256,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='same',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7e6eff-927a-4736-9ac7-fefbb76e0a75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256, 256, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 128, 128, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 126, 126, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 126, 126, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 63, 63, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 63, 63, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 63, 63, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 31, 31, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 123008)            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               15745152  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,847,617\n",
      "Trainable params: 15,847,169\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d71cec3f-d083-4578-98c9-dfce0c9040ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.001,momentum=0.9)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35779d79-5cd2-4927-b4d4-c9939f1b650a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 3s 114ms/step - loss: 0.1726 - accuracy: 0.9375 - val_loss: 2.3338 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 2s 113ms/step - loss: 0.2975 - accuracy: 0.8906 - val_loss: 2.9367 - val_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 2s 111ms/step - loss: 0.2169 - accuracy: 0.9271 - val_loss: 3.0912 - val_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 3s 159ms/step - loss: 0.1081 - accuracy: 0.9688 - val_loss: 4.0204 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 4s 159ms/step - loss: 0.1169 - accuracy: 0.9583 - val_loss: 4.6770 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 3s 143ms/step - loss: 0.1058 - accuracy: 0.9531 - val_loss: 4.8853 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 3s 130ms/step - loss: 0.0617 - accuracy: 0.9792 - val_loss: 5.3333 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 3s 126ms/step - loss: 0.0480 - accuracy: 0.9740 - val_loss: 5.7645 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "20/20 [==============================] - 3s 132ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 5.9657 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "20/20 [==============================] - 3s 129ms/step - loss: 0.0366 - accuracy: 0.9896 - val_loss: 5.5645 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "20/20 [==============================] - 3s 126ms/step - loss: 0.0222 - accuracy: 0.9896 - val_loss: 5.3943 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 0.0162 - accuracy: 0.9896 - val_loss: 5.2695 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "20/20 [==============================] - 3s 129ms/step - loss: 0.0307 - accuracy: 0.9948 - val_loss: 4.9108 - val_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "20/20 [==============================] - 3s 121ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 3.9449 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "20/20 [==============================] - 3s 123ms/step - loss: 0.0299 - accuracy: 0.9844 - val_loss: 3.3354 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 0.0201 - accuracy: 0.9895"
     ]
    }
   ],
   "source": [
    "model.fit(train_data,epochs=20,validation_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a46261-9d55-42c5-a9e2-04ec487573b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d66ed4-01f1-46d8-9149-2227f1bdadc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'images/test/room.jpg'\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img,(256,256))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "img = img.reshape((1,256,256,3))\n",
    "pred = \"Clean\" if model.predict(img)[0] >= 0.5 else \"Messy\"\n",
    "plt.title(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721730f8-337d-4785-953f-1f667f4427c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,5,figsize=(16,8))\n",
    "k=0\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        path = f'images/test/{k}.png'\n",
    "        k+=1\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        axes[i][j].imshow(img)\n",
    "        axes[i][j].axis('off')\n",
    "        img = img.reshape((1,256,256,3))\n",
    "        img = tf.cast(img,tf.float32)\n",
    "        pred = \"Clean\" if model.predict(img)[0] >= 0.5 else \"Messy\"\n",
    "        axes[i][j].set_title(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7455fd-cc50-40fb-a683-93168cb35bf6",
   "metadata": {},
   "source": [
    "# Using Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d7729a-b35b-4bf2-9700-e8e69e44d898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01edaab-2fd7-4019-aabe-15bffce5ac54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
    " width_shift_range=0.2, height_shift_range=0.2,rotation_range=10,zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a9d8f-f731-4f91-818e-399ebfcd20e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_datagen.flow_from_directory('images/train/',\n",
    "    class_mode='binary', batch_size=10, target_size=(256, 256))\n",
    "test = test_datagen.flow_from_directory('images/val/',\n",
    "    class_mode='binary', batch_size=10, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd795c79-8f66-4d1a-8523-32aaf806645d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c4fc87-e4e6-4363-9bd2-a0bc52b4db7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49179ac6-b9a5-4388-a5ce-1c27617e4344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(train,validation_data=test,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf3097-01e8-4de6-b2fc-71a4e155663a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,5,figsize=(16,8))\n",
    "k=0\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        path = f'images/test/{k}.png'\n",
    "        k+=1\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img,(256,256))\n",
    "        axes[i][j].imshow(img)\n",
    "        axes[i][j].axis('off')\n",
    "        img = img.reshape((1,256,256,3))\n",
    "        img = tf.cast(img,tf.float32)\n",
    "        pred = \"Clean\" if model.predict(img)[0] >= 0.5 else \"Messy\"\n",
    "        axes[i][j].set_title(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

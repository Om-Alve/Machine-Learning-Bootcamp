{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2eadd48-7b7e-486a-8c57-d4e5b2ee2980",
      "metadata": {
        "tags": [],
        "id": "b2eadd48-7b7e-486a-8c57-d4e5b2ee2980"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Conv2D,MaxPool2D,Flatten,BatchNormalization,Dropout\n",
        "from keras.optimizers import Adam,SGD\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import wave\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "959ec82c-b890-4700-a6ea-aac86b2a4cdb",
      "metadata": {
        "tags": [],
        "id": "959ec82c-b890-4700-a6ea-aac86b2a4cdb"
      },
      "outputs": [],
      "source": [
        "# wav.readframes(-1) reads all the frames and returns a bytestring, we convert\n",
        "# that into an array using np.frombuffer\n",
        "# wav.getframerate() returns the frame rate\n",
        "data = 'audio_to_image/'\n",
        "def create_image(wav_file,count):\n",
        "    wav = wave.open(wav_file,'r')\n",
        "    out = plt.specgram(np.frombuffer(wav.readframes(-1),np.int16),wav.getframerate())\n",
        "    class_label = os.path.basename(wav_file).split('_')[0]  # Modify this based on your file naming convention\n",
        "  # Create directory if it doesn't exist\n",
        "    output_directory = os.path.join(data, class_label)\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "    plt.savefig(os.path.join(output_directory, f'{count}.png'))\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4311dc5c-f564-4484-b0e8-91562947f78a",
      "metadata": {
        "tags": [],
        "id": "4311dc5c-f564-4484-b0e8-91562947f78a"
      },
      "outputs": [],
      "source": [
        "path = 'free-spoken-digit-dataset-master/recordings/'\n",
        "files = os.listdir(path)\n",
        "for i,f in tqdm(enumerate(files)):\n",
        "    create_image(path+f,i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff77d0f-feb3-4491-84ba-abe9706a8583",
      "metadata": {
        "tags": [],
        "id": "0ff77d0f-feb3-4491-84ba-abe9706a8583"
      },
      "outputs": [],
      "source": [
        "arr =plt.imread('audio_to_image/1/301.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4ab721-1b3b-4ec5-957c-fc8ffad0935c",
      "metadata": {
        "tags": [],
        "id": "cd4ab721-1b3b-4ec5-957c-fc8ffad0935c",
        "outputId": "0f108a55-6555-4fec-b9e9-a79c09c11cf9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(480, 640, 4)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "BATCH_SIZE = 64\n",
        "CHANNELS = 3\n",
        "CLASSES = 10\n",
        "\n",
        "\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             directory=os.path.join('audio_to_image'),\n",
        "                                             shuffle=True,\n",
        "                                             color_mode='rgb',\n",
        "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                             subset=\"training\",\n",
        "                                             seed=0)\n",
        "\n",
        "val_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             directory=os.path.join('audio_to_image'),\n",
        "                                             shuffle=True,\n",
        "                                             color_mode='rgb',\n",
        "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                             subset=\"validation\",\n",
        "                                             seed=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkM8RAbbhTWm",
        "outputId": "b12cfd7a-496a-40bd-f8ca-ff74ac841a56"
      },
      "id": "UkM8RAbbhTWm",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3003 files belonging to 10 classes.\n",
            "Using 2403 files for training.\n",
            "Found 3003 files belonging to 10 classes.\n",
            "Using 600 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "809c5cbb-3222-4f7f-89ee-152dc2b1001a",
      "metadata": {
        "tags": [],
        "id": "809c5cbb-3222-4f7f-89ee-152dc2b1001a"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)))\n",
        "model.add(Conv2D(32,3,strides=2,padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
        "model.add(Conv2D(64,3,strides=2,padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
        "model.add(Conv2D(128,3,strides=2,padding='same',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(CLASSES,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yu4gV9M7dU03",
        "outputId": "f9bb5ae4-e956-4730-b732-8b6d0e97fcf5"
      },
      "id": "yu4gV9M7dU03",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_22 (Conv2D)          (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization_32 (Ba  (None, 128, 128, 32)      128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPooli  (None, 64, 64, 32)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_33 (Ba  (None, 32, 32, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPooli  (None, 16, 16, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_34 (Ba  (None, 8, 8, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPooli  (None, 4, 4, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               524544    \n",
            "                                                                 \n",
            " batch_normalization_35 (Ba  (None, 256)               1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 653898 (2.49 MB)\n",
            "Trainable params: 652938 (2.49 MB)\n",
            "Non-trainable params: 960 (3.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2db9bf7-0937-4618-a490-a31ccefd8ee0",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2db9bf7-0937-4618-a490-a31ccefd8ee0",
        "outputId": "960db9f8-6014-4e12-a25c-205a36d8aab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "76/76 [==============================] - 19s 198ms/step - loss: 0.2924 - accuracy: 0.9047 - val_loss: 0.9418 - val_accuracy: 0.7717\n",
            "Epoch 2/20\n",
            "76/76 [==============================] - 18s 227ms/step - loss: 0.2937 - accuracy: 0.8960 - val_loss: 0.7610 - val_accuracy: 0.7817\n",
            "Epoch 3/20\n",
            "76/76 [==============================] - 16s 203ms/step - loss: 0.2470 - accuracy: 0.9114 - val_loss: 0.6568 - val_accuracy: 0.8267\n",
            "Epoch 4/20\n",
            "76/76 [==============================] - 17s 207ms/step - loss: 0.2215 - accuracy: 0.9230 - val_loss: 1.0446 - val_accuracy: 0.7467\n",
            "Epoch 5/20\n",
            "76/76 [==============================] - 17s 211ms/step - loss: 0.2220 - accuracy: 0.9222 - val_loss: 0.7594 - val_accuracy: 0.7900\n",
            "Epoch 6/20\n",
            "76/76 [==============================] - 17s 204ms/step - loss: 0.2254 - accuracy: 0.9255 - val_loss: 0.8745 - val_accuracy: 0.7783\n",
            "Epoch 7/20\n",
            "76/76 [==============================] - 19s 230ms/step - loss: 0.1928 - accuracy: 0.9372 - val_loss: 0.8223 - val_accuracy: 0.8067\n",
            "Epoch 8/20\n",
            "76/76 [==============================] - 16s 202ms/step - loss: 0.1868 - accuracy: 0.9338 - val_loss: 0.6728 - val_accuracy: 0.8250\n",
            "Epoch 9/20\n",
            "76/76 [==============================] - 19s 232ms/step - loss: 0.1802 - accuracy: 0.9413 - val_loss: 0.8678 - val_accuracy: 0.7967\n",
            "Epoch 10/20\n",
            "76/76 [==============================] - 17s 199ms/step - loss: 0.1789 - accuracy: 0.9376 - val_loss: 0.7430 - val_accuracy: 0.8033\n",
            "Epoch 11/20\n",
            "76/76 [==============================] - 16s 201ms/step - loss: 0.1305 - accuracy: 0.9534 - val_loss: 0.6174 - val_accuracy: 0.8417\n",
            "Epoch 12/20\n",
            "76/76 [==============================] - 16s 202ms/step - loss: 0.1595 - accuracy: 0.9422 - val_loss: 0.4948 - val_accuracy: 0.8600\n",
            "Epoch 13/20\n",
            "76/76 [==============================] - 16s 202ms/step - loss: 0.1753 - accuracy: 0.9417 - val_loss: 0.5983 - val_accuracy: 0.8517\n",
            "Epoch 14/20\n",
            "76/76 [==============================] - 16s 202ms/step - loss: 0.1377 - accuracy: 0.9559 - val_loss: 0.7764 - val_accuracy: 0.8117\n",
            "Epoch 15/20\n",
            "76/76 [==============================] - 17s 205ms/step - loss: 0.1485 - accuracy: 0.9530 - val_loss: 1.1387 - val_accuracy: 0.7733\n",
            "Epoch 16/20\n",
            "76/76 [==============================] - 19s 232ms/step - loss: 0.1463 - accuracy: 0.9509 - val_loss: 1.3435 - val_accuracy: 0.7217\n",
            "Epoch 17/20\n",
            "76/76 [==============================] - 17s 203ms/step - loss: 0.1220 - accuracy: 0.9576 - val_loss: 0.7111 - val_accuracy: 0.8517\n",
            "Epoch 18/20\n",
            "76/76 [==============================] - 18s 217ms/step - loss: 0.1361 - accuracy: 0.9517 - val_loss: 0.5612 - val_accuracy: 0.8600\n",
            "Epoch 19/20\n",
            "76/76 [==============================] - 16s 201ms/step - loss: 0.1600 - accuracy: 0.9513 - val_loss: 0.7840 - val_accuracy: 0.7983\n",
            "Epoch 20/20\n",
            "76/76 [==============================] - 19s 218ms/step - loss: 0.1272 - accuracy: 0.9567 - val_loss: 1.4562 - val_accuracy: 0.7133\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=tf.keras.optimizers.RMSprop(),metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_dataset, epochs=20, validation_data=val_dataset,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wav.readframes(-1) reads all the frames and returns a bytestring, we convert\n",
        "# that into an array using np.frombuffer\n",
        "# wav.getframerate() returns the frame rate\n",
        "\n",
        "def predict(wav_file):\n",
        "    wav = wave.open(wav_file,'r')\n",
        "    out = plt.specgram(np.frombuffer(wav.readframes(-1),np.int16),wav.getframerate())\n",
        "    plt.savefig('out.png')\n",
        "    plt.imread('out.png')\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "cPJHdTqrqIRt"
      },
      "id": "cPJHdTqrqIRt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wav = wave.open(\"recordings_0_george_0.wav\",'r')\n",
        "# out = plt.specgram(np.frombuffer(wav.readframes(-1),np.int16),wav.getframerate())\n",
        "# plt.savefig('')\n",
        "plt.close()\n",
        "out = tf.keras.utils.load_img(\n",
        "    'audio_to_image/9/2786.png',\n",
        "    color_mode='rgb',\n",
        "    target_size=(256,256),\n",
        "    interpolation='nearest',\n",
        "    keep_aspect_ratio=False\n",
        ")\n",
        "out = np.expand_dims(out,axis=0)\n",
        "np.argmax(model.predict(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iae39P_wyiFH",
        "outputId": "9f86f278-e22b-4e34-ad71-f0874e90986d"
      },
      "id": "Iae39P_wyiFH",
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCc13Q9m3gJS",
        "outputId": "31b66728-41d5-4194-cb15-41d8d7553ef2"
      },
      "id": "HCc13Q9m3gJS",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.1432675e-04, 8.5397250e-10, 8.6906837e-10, 3.3344670e-13,\n",
              "        8.9090103e-01, 8.3814934e-02, 2.4816871e-02, 5.3972023e-08,\n",
              "        3.5279038e-04, 2.3688623e-08]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CNN model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)))\n",
        "model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(CLASSES, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train model for 10 epochs, capture the history\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlm755mk3zwS",
        "outputId": "b8f17647-9cd7-4d3b-ef6e-5cc5b71e0934"
      },
      "id": "tlm755mk3zwS",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "38/38 [==============================] - 20s 382ms/step - loss: 1.2864 - accuracy: 0.5747 - val_loss: 8.5739 - val_accuracy: 0.1000\n",
            "Epoch 2/10\n",
            "38/38 [==============================] - 17s 381ms/step - loss: 0.6323 - accuracy: 0.7840 - val_loss: 2.3647 - val_accuracy: 0.3167\n",
            "Epoch 3/10\n",
            "38/38 [==============================] - 18s 383ms/step - loss: 0.4348 - accuracy: 0.8598 - val_loss: 0.9778 - val_accuracy: 0.6433\n",
            "Epoch 4/10\n",
            "38/38 [==============================] - 17s 390ms/step - loss: 0.3402 - accuracy: 0.8943 - val_loss: 0.8867 - val_accuracy: 0.6683\n",
            "Epoch 5/10\n",
            "38/38 [==============================] - 16s 362ms/step - loss: 0.2565 - accuracy: 0.9197 - val_loss: 0.6616 - val_accuracy: 0.7667\n",
            "Epoch 6/10\n",
            "38/38 [==============================] - 16s 375ms/step - loss: 0.2180 - accuracy: 0.9351 - val_loss: 0.8571 - val_accuracy: 0.7317\n",
            "Epoch 7/10\n",
            "38/38 [==============================] - 17s 382ms/step - loss: 0.1756 - accuracy: 0.9484 - val_loss: 0.5235 - val_accuracy: 0.8283\n",
            "Epoch 8/10\n",
            "38/38 [==============================] - 17s 379ms/step - loss: 0.1482 - accuracy: 0.9605 - val_loss: 0.5057 - val_accuracy: 0.8283\n",
            "Epoch 9/10\n",
            "38/38 [==============================] - 17s 385ms/step - loss: 0.1207 - accuracy: 0.9692 - val_loss: 0.5700 - val_accuracy: 0.8083\n",
            "Epoch 10/10\n",
            "38/38 [==============================] - 16s 372ms/step - loss: 0.0988 - accuracy: 0.9738 - val_loss: 0.6116 - val_accuracy: 0.8133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i1A35FWV5KQW"
      },
      "id": "i1A35FWV5KQW",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:py39] *",
      "language": "python",
      "name": "conda-env-py39-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
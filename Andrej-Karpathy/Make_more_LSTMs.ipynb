{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "326ea1f4-5867-4ed0-b1aa-d9e29fe20d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "755f14ea-78be-46ad-816d-d126875caec2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('indian_names.txt','r').read().splitlines()\n",
    "words = [word.lower() for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b279420b-7b8d-477d-a0ba-6bf5b894a23b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = ['.'] + sorted(list(set(''.join(words))))\n",
    "stoi = {v:i for i,v in enumerate(vocab)}\n",
    "itos = {v:k for k,v in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "d5d10e5f-19fc-4810-b2f6-7354899225f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding,Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "97de6bda-f09c-4163-af3d-c848db34ce35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize the names at character level\n",
    "# words = [word + '.' for word in words]\n",
    "sequences = []\n",
    "for word in words:\n",
    "    seq = [stoi[c] for c in word]\n",
    "    sequences.append(seq)\n",
    "# Create input sequences and labels\n",
    "X = []\n",
    "y = []\n",
    "for seq in sequences:\n",
    "    for i in range(1, len(seq)):\n",
    "        X.append(seq[:i])\n",
    "        y.append(seq[i])\n",
    "    X.append(seq)\n",
    "    y.append(0)\n",
    "    \n",
    "# Pad sequences for consistent input shape\n",
    "max_seq_length = max([len(seq) for seq in X])\n",
    "X = pad_sequences(X, maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "# One-hot encode labels\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=len(stoi) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "02800897-83a6-42ab-b716-9c26eaafde78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "4ff41d30-ce20-4547-9dc8-e0605bf93d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "761c9d3b-534b-4c61-ade9-468a0e0c5434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(stoi) + 1, 32, input_length=max_seq_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(stoi) + 1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e73aa241-bf22-4254-820e-83101ee6c469",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "298/298 [==============================] - 31s 27ms/step - loss: 2.0583 - val_loss: 2.0407\n",
      "Epoch 2/10\n",
      "298/298 [==============================] - 7s 25ms/step - loss: 2.0444 - val_loss: 2.0188\n",
      "Epoch 3/10\n",
      "298/298 [==============================] - 8s 25ms/step - loss: 2.0247 - val_loss: 2.0140\n",
      "Epoch 4/10\n",
      "298/298 [==============================] - 7s 24ms/step - loss: 2.0189 - val_loss: 2.0060\n",
      "Epoch 5/10\n",
      "298/298 [==============================] - 7s 24ms/step - loss: 2.0108 - val_loss: 2.0028\n",
      "Epoch 6/10\n",
      "298/298 [==============================] - 7s 24ms/step - loss: 1.9887 - val_loss: 1.9975\n",
      "Epoch 7/10\n",
      "298/298 [==============================] - 7s 24ms/step - loss: 1.9824 - val_loss: 1.9910\n",
      "Epoch 8/10\n",
      "298/298 [==============================] - 7s 24ms/step - loss: 1.9694 - val_loss: 1.9844\n",
      "Epoch 9/10\n",
      "298/298 [==============================] - 7s 23ms/step - loss: 1.9515 - val_loss: 1.9793\n",
      "Epoch 10/10\n",
      "298/298 [==============================] - 7s 24ms/step - loss: 1.9393 - val_loss: 1.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2211a3a3c70>"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.fit(X_train, y_train,validation_data=(X_test,y_test), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "a5be72ce-1e58-496d-89e4-ca32e41ebef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_name(model,temperature):\n",
    "    seed_text = itos[np.random.randint(0,27)]\n",
    "    generated_text = \"\"\n",
    "    \n",
    "    while True:\n",
    "        sequence = [stoi[c] for c in seed_text]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_seq_length, padding='pre')\n",
    "\n",
    "        predicted_probabilities = model.predict(sequence)\n",
    "        predicted_probabilities/=temperature\n",
    "        predicted_id = tf.random.categorical(\n",
    "        predicted_probabilities,\n",
    "        num_samples=1\n",
    "        )[-1,0].numpy()\n",
    "        if predicted_id == len(stoi):\n",
    "            continue\n",
    "        if predicted_id == 0:\n",
    "            break\n",
    "        generated_text += itos[predicted_id]\n",
    "        seed_text += itos[predicted_id]\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "6d225280-dd35-4ce0-9c33-8425ec5dde90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "for i in range(10):\n",
    "    names.append(generate_name(model,0.06))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "f5782e29-8987-4404-9537-6f0b4f123188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ranal',\n",
       " 'arari',\n",
       " 'haaya',\n",
       " 'apan',\n",
       " 'aman',\n",
       " 'anish',\n",
       " 'anhan',\n",
       " 'ashi',\n",
       " 'aixa',\n",
       " 'ika']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
